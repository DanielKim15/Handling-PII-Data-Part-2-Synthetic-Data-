{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to turn any file or query into a pandas dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def file_or_sql_to_dataframe(source, save_csv=False, csv_filename=None, sql_connection=None):\n",
    "    \"\"\"\n",
    "    Reads a file (txt, json, excel, or sql query), all files in a directory, or a zip archive and converts it into a pandas DataFrame.\n",
    "    Optionally saves the DataFrame as a CSV file.\n",
    "\n",
    "    Args:\n",
    "        source (str): Path to the file, directory, zip archive, or SQL query.\n",
    "        save_csv (bool): Whether to save the DataFrame as a CSV file.\n",
    "        csv_filename (str): Filename to save the CSV file as (optional).\n",
    "        sql_connection (str or connection object): SQL connection string or connection object.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame created from the file(s) or SQL query.\n",
    "    \"\"\"\n",
    "    def read_files_from_dir(directory):\n",
    "        \"\"\"Read and concatenate all txt and json files in the directory into a DataFrame\"\"\"\n",
    "        file_paths = glob.glob(os.path.join(directory, '*.txt')) + glob.glob(os.path.join(directory, '*.json'))\n",
    "        dfs = []\n",
    "        for file_path in file_paths:\n",
    "            file_extension = os.path.splitext(file_path)[-1].lower()\n",
    "            if file_extension == '.txt':\n",
    "                df = pd.read_csv(file_path, delimiter='\\t', encoding='utf-8')\n",
    "            elif file_extension == '.json':\n",
    "                df = pd.read_json(file_path)\n",
    "            else:\n",
    "                continue\n",
    "            dfs.append(df)\n",
    "        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "    if sql_connection is not None:\n",
    "        conn = sqlite3.connect(sql_connection) if isinstance(sql_connection, str) else sql_connection\n",
    "        df = pd.read_sql(source, conn)\n",
    "    elif os.path.isdir(source):\n",
    "        df = read_files_from_dir(source)\n",
    "    elif os.path.splitext(source)[-1].lower() == '.zip':\n",
    "        with ZipFile(source, 'r') as zip_ref:\n",
    "            temp_dir = 'temp_extracted_files'\n",
    "            os.makedirs(temp_dir, exist_ok=True)\n",
    "            zip_ref.extractall(temp_dir)\n",
    "            df = read_files_from_dir(temp_dir)\n",
    "            for file in os.listdir(temp_dir):\n",
    "                os.remove(os.path.join(temp_dir, file))\n",
    "            os.rmdir(temp_dir)\n",
    "    else:\n",
    "        if source.endswith('.txt'):\n",
    "            df = pd.read_csv(source, delimiter='\\t', encoding='utf-8')\n",
    "        elif source.endswith('.json'):\n",
    "            df = pd.read_json(source)\n",
    "        elif source.endswith(('.xls', '.xlsx')):\n",
    "            df = pd.read_excel(source)\n",
    "        elif source.endswith('.csv'):\n",
    "            df = pd.read_csv(source)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type. File must be .txt, .json, .xls, .xlsx, .zip, or SQL query.\")\n",
    "\n",
    "    if save_csv and not df.empty:\n",
    "        csv_filename = csv_filename or os.path.splitext(source)[0] + '.csv'\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"Data saved as CSV file: {csv_filename}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# df = file_or_sql_to_dataframe('path/to/your/file.txt', save_csv=True)\n",
    "# df = file_or_sql_to_dataframe('path/to/your/directory')\n",
    "# df = file_or_sql_to_dataframe('path/to/your/zipfile.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50438, 40)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = file_or_sql_to_dataframe(\"C:/Users/dkim//Downloads/dataverse_files.zip\")\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120552, 82)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = file_or_sql_to_dataframe(\"C:/Users/dkim//Downloads/Emergency_Connectivity_Fund_FCC_Form_471_20231229 - Copy.txt\")\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31463, 82)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "ecf_data = pd.read_csv(\"C:/Users/dkim//Downloads/Emergency_Connectivity_Fund_FCC_Form_471_20231229.csv\")\n",
    "ecf_data.describe()\n",
    "ecf_data = ecf_data[ecf_data['Form Version'] == 'Current']\n",
    "\n",
    "ecf_data_sample = ecf_data.sample(frac=0.5) #this is to select on 50% of the data\n",
    "ecf_data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#developing a unique identifier\n",
    "ecf_data_sample['unique_key'] = ecf_data_sample['Funding Request Number (FRN)'].astype(str) + '_' + ecf_data_sample['FRN Line Item ID'].astype(str) + '_' + ecf_data_sample['One-time Unit Cost'].astype(str) + '_' + ecf_data_sample['One-time Unit Quantity'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44041     ECF2190007284_1_327.0_250\n",
       "39517         ECF2290010096_2_0.0_0\n",
       "63522         ECF2190007775_1_0.0_0\n",
       "114165        ECF2190027746_2_0.0_1\n",
       "18920     ECF2290007014_1_394.25_20\n",
       "                    ...            \n",
       "102379        ECF2190033360_1_0.0_0\n",
       "39564      ECF2190004899_3_400.0_20\n",
       "114121    ECF2190027662_3_335.19_25\n",
       "4785        ECF2290010869_3_264.0_6\n",
       "84860      ECF2190013111_3_50.0_110\n",
       "Name: unique_key, Length: 31463, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecf_data_sample['unique_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31463, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecf_data_sample_selected = ecf_data_sample.loc[:, ['Application Number', 'unique_key', 'Total Funding Commitment Request Amount', 'Product Type', 'Urban/ Rural Status', 'Monthly Recurring Unit Cost', 'Total Student Count']]\n",
    "ecf_data_sample_selected.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = SingleTableMetadata() #this is set up before hand to prepare for the evalutaion testing\n",
    "metadata.detect_from_dataframe(data=ecf_data_sample_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import TVAESynthesizer, GaussianCopulaSynthesizer, CTGANSynthesizer, CopulaGANSynthesizer\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.evaluation.single_table import get_column_plot, evaluate_quality, get_column_pair_plot\n",
    "\n",
    "def generate_synthetic_data(dataset, sdv_type, unique_id, num_samples):\n",
    "    \"\"\"\n",
    "    Generates synthetic data using the specified SDV synthesizer.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset to base the synthetic data on.\n",
    "        sdv_type (str): Type of SDV synthesizer to use ('TVAE', 'GaussianCopula', 'CopulaGAN', 'fast_ml', or 'CTGAN').\n",
    "        unique_id (str): Column name to set as a primary key in the dataset.\n",
    "        num_samples (int): Number of synthetic data rows to generate.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The generated synthetic dataset.\n",
    "    \"\"\"\n",
    "    # Create metadata object and detect from dataframe\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(data=dataset)\n",
    "    \n",
    "    # Update metadata for the unique key column\n",
    "    metadata.update_column(column_name=unique_id, sdtype='id')\n",
    "    metadata.set_primary_key(column_name=unique_id)\n",
    "    \n",
    "    # Validate metadata\n",
    "    metadata.validate_data(data=dataset) #if there is an error it will provide an in depth look in the error\n",
    "    \n",
    "    # Select the synthesizer based on sdv_type\n",
    "    if sdv_type == 'TVAE':\n",
    "        synthesizer = TVAESynthesizer(\n",
    "                        metadata, # required\n",
    "                        enforce_min_max_values=True,\n",
    "                        enforce_rounding=True,\n",
    "                        epochs=500) \n",
    "    elif sdv_type == 'GaussianCopula':\n",
    "        synthesizer = GaussianCopulaSynthesizer(\n",
    "                        metadata, \n",
    "                        enforce_min_max_values=True,\n",
    "                        enforce_rounding=True,\n",
    "                        #numerical_distributions={\n",
    "                        #    'amenities_fee': 'beta',\n",
    "                        #    'checkin_date': 'uniform'\n",
    "                        #        },\n",
    "                        #default_distribution='norm' #lets you determine what distrubution your working  with, read file for more information: https://docs.sdv.dev/sdv/single-table-data/modeling/synthesizers/gaussiancopulasynthesizer\n",
    "                        )\n",
    "    elif sdv_type == 'CTGAN':\n",
    "        synthesizer = CTGANSynthesizer(\n",
    "                        metadata, \n",
    "                        enforce_rounding=True,\n",
    "                        epochs=500,\n",
    "                        verbose=True)\n",
    "    elif sdv_type == 'CopulaGAN':\n",
    "        synthesizer = CopulaGANSynthesizer(\n",
    "                        metadata, \n",
    "                        enforce_min_max_values=True,\n",
    "                        enforce_rounding=True,\n",
    "                     #   numerical_distributions={\n",
    "                     #       'amenities_fee': 'beta',\n",
    "                     #       'checkin_date': 'uniform'\n",
    "                     #                       },\n",
    "                        epochs=500,\n",
    "                        verbose=True)\n",
    "    elif sdv_type == 'fast_ml':\n",
    "        synthesizer = SingleTablePreset(metadata, name='FAST_ML')\n",
    "    else:\n",
    "        return \"Error: Invalid SDV synthesizer type. Choose 'TVAE', 'GaussianCopula', 'CopulaGAN', 'fast_ml', or 'CTGAN'.\"\n",
    "\n",
    "    # Fit the synthesizer on the dataset\n",
    "    synthesizer.fit(dataset)\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    synthetic_data = synthesizer.sample(num_rows=num_samples)\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# Example usage\n",
    "# synthetic_dataset = generate_synthetic_data(ecf_data_sample_selected, 'TVAE', 'unique_key', 25000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_dataset = generate_synthetic_data(ecf_data_sample_selected, 'TVAE',\"unique_key\", 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_dataset = generate_synthetic_data(ecf_data_sample_selected, 'GaussianCopula',\"unique_key\", 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Data Validity: : 100%|██████████| 7/7 [00:00<00:00, 368.31it/s]\n",
      "(2/2) Evaluating Data Structure: : 100%|██████████| 1/1 [00:00<00:00, 499.14it/s]\n",
      "\n",
      "Overall Score: 100.0%\n",
      "\n",
      "Properties:\n",
      "- Data Validity: 100.0%\n",
      "- Data Structure: 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sdv.evaluation.single_table import run_diagnostic\n",
    "\n",
    "diagnostic_report = run_diagnostic( #this is to ensure that the model has worked properly. Anything lower than a 100 is a problem and should be taken care of\n",
    "    real_data=ecf_data_sample_selected,\n",
    "    synthetic_data=synthetic_dataset,\n",
    "    metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 7/7 [00:00<00:00, 87.19it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 21/21 [00:00<00:00, 56.76it/s] \n",
      "\n",
      "Overall Score: 63.6%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 88.66%\n",
      "- Column Pair Trends: 38.53%\n"
     ]
    }
   ],
   "source": [
    "quality_report = evaluate_quality( \n",
    "    real_data=ecf_data_sample_selected, #also this is the model without hyperparameter trained\n",
    "    synthetic_data=synthetic_dataset,\n",
    "    metadata=metadata #63% overal score, column shapes is 87%, column pair trends is 38% if the model is not trained hyperparameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Funding Commitment Request Amount</td>\n",
       "      <td>KSComplement</td>\n",
       "      <td>0.932573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Type</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.919209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urban/ Rural Status</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.983609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monthly Recurring Unit Cost</td>\n",
       "      <td>KSComplement</td>\n",
       "      <td>0.669842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total Student Count</td>\n",
       "      <td>KSComplement</td>\n",
       "      <td>0.927928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Column        Metric     Score\n",
       "0  Total Funding Commitment Request Amount  KSComplement  0.932573\n",
       "1                             Product Type  TVComplement  0.919209\n",
       "2                      Urban/ Rural Status  TVComplement  0.983609\n",
       "3              Monthly Recurring Unit Cost  KSComplement  0.669842\n",
       "4                      Total Student Count  KSComplement  0.927928"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_report.get_details(property_name='Column Shapes') #shows the accuracy in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.evaluation.single_table import get_column_plot\n",
    "import plotly.io as pio\n",
    "\n",
    "# This ensures Plotly plots show up in Jupyter notebooks\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "fig = get_column_plot(\n",
    "    real_data=ecf_data_sample_selected,\n",
    "    synthetic_data=synthetic_dataset,\n",
    "    metadata=metadata,\n",
    "    column_name='Total Funding Commitment Request Amount'\n",
    ")\n",
    "\n",
    "# Show the figure using Plotly's show method\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.evaluation.single_table import get_column_pair_plot\n",
    "\n",
    "fig = get_column_pair_plot(\n",
    "    real_data=ecf_data_sample_selected,\n",
    "    synthetic_data=synthetic_dataset,\n",
    "    metadata=metadata,\n",
    "    column_names=['Total Funding Commitment Request Amount', 'Total Student Count'],\n",
    "    )\n",
    "    \n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
