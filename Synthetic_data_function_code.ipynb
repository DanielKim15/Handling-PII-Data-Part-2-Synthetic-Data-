{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to turn any file or query into a pandas dataframe\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def file_or_sql_to_dataframe(source, save_csv=False, csv_filename=None, sql_connection=None):\n",
    "    \"\"\"\n",
    "    Reads a file (txt, json, excel, or sql query), all files in a directory, or a zip archive and converts it into a pandas DataFrame.\n",
    "    Optionally saves the DataFrame as a CSV file.\n",
    "\n",
    "    Args:\n",
    "        source (str): Path to the file, directory, zip archive, or SQL query.\n",
    "        save_csv (bool): Whether to save the DataFrame as a CSV file.\n",
    "        csv_filename (str): Filename to save the CSV file as (optional).\n",
    "        sql_connection (str or connection object): SQL connection string or connection object.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame created from the file(s) or SQL query.\n",
    "    \"\"\"\n",
    "    def read_files_from_dir(directory):\n",
    "        \"\"\"Read and concatenate all txt and json files in the directory into a DataFrame\"\"\"\n",
    "        file_paths = glob.glob(os.path.join(directory, '*.txt')) + glob.glob(os.path.join(directory, '*.json'))\n",
    "        dfs = []\n",
    "        for file_path in file_paths:\n",
    "            file_extension = os.path.splitext(file_path)[-1].lower()\n",
    "            if file_extension == '.txt':\n",
    "                df = pd.read_csv(file_path, delimiter='\\t', encoding='utf-8')\n",
    "            elif file_extension == '.json':\n",
    "                df = pd.read_json(file_path)\n",
    "            else:\n",
    "                continue\n",
    "            dfs.append(df)\n",
    "        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
    "\n",
    "    if sql_connection is not None:\n",
    "        conn = sqlite3.connect(sql_connection) if isinstance(sql_connection, str) else sql_connection\n",
    "        df = pd.read_sql(source, conn)\n",
    "    elif os.path.isdir(source):\n",
    "        df = read_files_from_dir(source)\n",
    "    elif os.path.splitext(source)[-1].lower() == '.zip':\n",
    "        with ZipFile(source, 'r') as zip_ref:\n",
    "            temp_dir = 'temp_extracted_files'\n",
    "            os.makedirs(temp_dir, exist_ok=True)\n",
    "            zip_ref.extractall(temp_dir)\n",
    "            df = read_files_from_dir(temp_dir)\n",
    "            for file in os.listdir(temp_dir):\n",
    "                os.remove(os.path.join(temp_dir, file))\n",
    "            os.rmdir(temp_dir)\n",
    "    else:\n",
    "        if source.endswith('.txt'):\n",
    "            df = pd.read_csv(source, delimiter='\\t', encoding='utf-8')\n",
    "        elif source.endswith('.json'):\n",
    "            df = pd.read_json(source)\n",
    "        elif source.endswith(('.xls', '.xlsx')):\n",
    "            df = pd.read_excel(source)\n",
    "        elif source.endswith('.csv'):\n",
    "            df = pd.read_csv(source)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type. File must be .txt, .json, .xls, .xlsx, .zip, or SQL query.\")\n",
    "\n",
    "    if save_csv and not df.empty:\n",
    "        csv_filename = csv_filename or os.path.splitext(source)[0] + '.csv'\n",
    "        df.to_csv(csv_filename, index=False)\n",
    "        print(f\"Data saved as CSV file: {csv_filename}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# df = file_or_sql_to_dataframe('path/to/your/file.txt', save_csv=True)\n",
    "# df = file_or_sql_to_dataframe('path/to/your/directory')\n",
    "# df = file_or_sql_to_dataframe('path/to/your/zipfile.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50438, 40)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = file_or_sql_to_dataframe(\"C:/Users/dkim//Downloads/dataverse_files.zip\")\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120552, 82)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = file_or_sql_to_dataframe(\"C:/Users/dkim//Downloads/Emergency_Connectivity_Fund_FCC_Form_471_20231229 - Copy.txt\")\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31463, 82)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "ecf_data = pd.read_csv(\"C:/Users/dkim/Downloads/Emergency_Connectivity_Fund_FCC_Form_471_20231229.csv\")\n",
    "ecf_data.describe()\n",
    "ecf_data = ecf_data[ecf_data['Form Version'] == 'Current']\n",
    "\n",
    "ecf_data_sample = ecf_data.sample(frac=0.5) #this is to select on 50% of the data\n",
    "ecf_data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#developing a unique identifier\n",
    "ecf_data_sample['unique_key'] = ecf_data_sample['Funding Request Number (FRN)'].astype(str) + '_' + ecf_data_sample['FRN Line Item ID'].astype(str) + '_' + ecf_data_sample['One-time Unit Cost'].astype(str) + '_' + ecf_data_sample['One-time Unit Quantity'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119046     ECF2190030719_2_55.95_10\n",
       "21560        ECF2190010981_1_73.0_5\n",
       "53919      ECF2190015060_1_308.0_44\n",
       "40164     ECF2190004956_1_203.0_825\n",
       "18450     ECF2290009423_2_399.0_700\n",
       "                    ...            \n",
       "26814         ECF2190030668_2_0.0_1\n",
       "8782       ECF2190016797_5_30.0_924\n",
       "8986      ECF2190034462_1_357.95_40\n",
       "56390         ECF2290013215_2_0.0_0\n",
       "23183       ECF2290011601_3_98.29_1\n",
       "Name: unique_key, Length: 31463, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecf_data_sample['unique_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31463, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecf_data_sample_selected = ecf_data_sample.loc[:, ['Application Number', 'unique_key', 'Total Funding Commitment Request Amount', 'Product Type', 'Urban/ Rural Status', 'Monthly Recurring Unit Cost', 'Total Student Count']]\n",
    "ecf_data_sample_selected.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = SingleTableMetadata() #this is set up before hand to prepare for the evalutaion testing\n",
    "metadata.detect_from_dataframe(data=ecf_data_sample_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import TVAESynthesizer, GaussianCopulaSynthesizer, CTGANSynthesizer, CopulaGANSynthesizer\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.evaluation.single_table import get_column_plot, evaluate_quality, get_column_pair_plot\n",
    "\n",
    "def generate_synthetic_data(dataset, sdv_type, unique_id, num_samples):\n",
    "    \"\"\"\n",
    "    Generates synthetic data using the specified SDV synthesizer.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The dataset to base the synthetic data on.\n",
    "        sdv_type (str): Type of SDV synthesizer to use ('TVAE', 'GaussianCopula', 'CopulaGAN', 'fast_ml', or 'CTGAN').\n",
    "        unique_id (str): Column name to set as a primary key in the dataset.\n",
    "        num_samples (int): Number of synthetic data rows to generate.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The generated synthetic dataset.\n",
    "    \"\"\"\n",
    "    # Create metadata object and detect from dataframe\n",
    "    metadata = SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(data=dataset)\n",
    "    \n",
    "    # Update metadata for the unique key column\n",
    "    metadata.update_column(column_name=unique_id, sdtype='id')\n",
    "    metadata.set_primary_key(column_name=unique_id)\n",
    "    \n",
    "    # Validate metadata\n",
    "    try:\n",
    "        metadata.validate()\n",
    "    except Exception as e:\n",
    "        return f\"Error: The metadata does not represent the structure and constraints of the data, try again. Details: {str(e)}\"\n",
    "    \n",
    "    # Select the synthesizer based on sdv_type\n",
    "    if sdv_type == 'TVAE':\n",
    "        synthesizer = TVAESynthesizer(\n",
    "                        metadata, # required\n",
    "                        enforce_min_max_values=True,\n",
    "                        enforce_rounding=True,\n",
    "                        epochs=500) \n",
    "    elif sdv_type == 'GaussianCopula':\n",
    "        synthesizer = GaussianCopulaSynthesizer(\n",
    "                        metadata, \n",
    "                        enforce_min_max_values=True,\n",
    "                        enforce_rounding=True,\n",
    "                        #numerical_distributions={\n",
    "                        #    'amenities_fee': 'beta',\n",
    "                        #    'checkin_date': 'uniform'\n",
    "                        #        },\n",
    "                        #default_distribution='norm' #lets you determine what distrubution your working  with, read file for more information: https://docs.sdv.dev/sdv/single-table-data/modeling/synthesizers/gaussiancopulasynthesizer\n",
    "                        )\n",
    "    elif sdv_type == 'CTGAN':\n",
    "        synthesizer = CTGANSynthesizer(\n",
    "                        metadata, \n",
    "                        enforce_rounding=True,\n",
    "                        epochs=500,\n",
    "                        verbose=True)\n",
    "    elif sdv_type == 'CopulaGAN':\n",
    "        synthesizer = CopulaGANSynthesizer(\n",
    "                        metadata, \n",
    "                        enforce_min_max_values=True,\n",
    "                        enforce_rounding=True,\n",
    "                     #   numerical_distributions={\n",
    "                     #       'amenities_fee': 'beta',\n",
    "                     #       'checkin_date': 'uniform'\n",
    "                     #                       },\n",
    "                        epochs=500,\n",
    "                        verbose=True)\n",
    "    elif sdv_type == 'fast_ml':\n",
    "        synthesizer = SingleTablePreset(metadata, name='FAST_ML')\n",
    "    else:\n",
    "        return \"Error: Invalid SDV synthesizer type. Choose 'TVAE', 'GaussianCopula', 'CopulaGAN', 'fast_ml', or 'CTGAN'.\"\n",
    "\n",
    "    # Fit the synthesizer on the dataset\n",
    "    synthesizer.fit(dataset)\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    synthetic_data = synthesizer.sample(num_rows=num_samples)\n",
    "    \n",
    "    return synthetic_data\n",
    "\n",
    "# Example usage\n",
    "# synthetic_dataset = generate_synthetic_data(ecf_data_sample_selected, 'TVAE', 'unique_key', 25000)\n"
   ]
  },
   "source": [
    "synthetic_dataset = generate_synthetic_data(ecf_data_sample_selected, 'TVAE',\"unique_key\", 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_dataset = generate_synthetic_data(ecf_data_sample_selected, 'GaussianCopula',\"unique_key\", 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report ...\n",
      "(1/2) Evaluating Column Shapes: : 100%|██████████| 7/7 [00:00<00:00, 89.30it/s]\n",
      "(2/2) Evaluating Column Pair Trends: : 100%|██████████| 21/21 [00:00<00:00, 59.42it/s] \n",
      "\n",
      "Overall Score: 63.58%\n",
      "\n",
      "Properties:\n",
      "- Column Shapes: 88.27%\n",
      "- Column Pair Trends: 38.89%\n"
     ]
    }
   ],
   "source": [
    "quality_report = evaluate_quality( \n",
    "    real_data=ecf_data_sample_selected, #also this is the model without hyperparameter trained\n",
    "    synthetic_data=synthetic_dataset,\n",
    "    metadata=metadata #63% overal score, column shapes is 87%, column pair trends is 38% if the model is not trained hyperparameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Funding Commitment Request Amount</td>\n",
       "      <td>KSComplement</td>\n",
       "      <td>0.929664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product Type</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.954854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urban/ Rural Status</td>\n",
       "      <td>TVComplement</td>\n",
       "      <td>0.967598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Monthly Recurring Unit Cost</td>\n",
       "      <td>KSComplement</td>\n",
       "      <td>0.642355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total Student Count</td>\n",
       "      <td>KSComplement</td>\n",
       "      <td>0.919156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Column        Metric     Score\n",
       "0  Total Funding Commitment Request Amount  KSComplement  0.929664\n",
       "1                             Product Type  TVComplement  0.954854\n",
       "2                      Urban/ Rural Status  TVComplement  0.967598\n",
       "3              Monthly Recurring Unit Cost  KSComplement  0.642355\n",
       "4                      Total Student Count  KSComplement  0.919156"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_report.get_details(property_name='Column Shapes') #shows the accuracy in details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
